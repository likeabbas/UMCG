diff --git a/Makefile b/Makefile
index 25176398b..052c433a9 100644
--- a/Makefile
+++ b/Makefile
@@ -147,6 +147,7 @@ RUNTIME_TESTS=	\
 ifeq ($(ARCH),x86_64)
 
 RUNTIME_TESTS+= \
+	umcg \
 	vsyscall \
 
 endif
diff --git a/klib/Makefile b/klib/Makefile
index 67fc27c13..9eab609d3 100644
--- a/klib/Makefile
+++ b/klib/Makefile
@@ -143,6 +143,15 @@ SRCS-mbedtls-tls= \
 	$(MBEDTLS_DIR)/library/ssl_ticket.c \
 	$(MBEDTLS_DIR)/library/ssl_tls.c \
 
+ifeq ($(ARCH),x86_64)
+
+PROGRAMS+= umcg
+
+SRCS-umcg= \
+	$(CURDIR)/umcg.c \
+
+endif
+
 ADDITIONAL_PROGRAMS= \
 	test/klib \
 	test/lock \
diff --git a/klib/umcg.c b/klib/umcg.c
new file mode 100644
index 000000000..6533804b1
--- /dev/null
+++ b/klib/umcg.c
@@ -0,0 +1,528 @@
+#include <unix_internal.h>
+
+#define SYS_umcg_ctl    450
+
+#define UMCG_WORKER_ID_SHIFT    5
+#define UMCG_WORKER_EVENT_MASK  ((1 << UMCG_WORKER_ID_SHIFT) - 1)
+
+enum umcg_cmd {
+    UMCG_REGISTER_WORKER = 1,
+    UMCG_REGISTER_SERVER,
+    UMCG_UNREGISTER,
+    UMCG_WAKE,
+    UMCG_WAIT,
+    UMCG_CTX_SWITCH,
+};
+
+#define UMCG_WAIT_FLAG_INTERRUPTED  (1ull)
+
+#define UMCG_CMD_KNOWN_FLAGS    UMCG_WAIT_FLAG_INTERRUPTED
+
+enum umcg_worker_status {
+    UMCG_WORKER_IDLE,
+    UMCG_WORKER_RUNNABLE,
+    UMCG_WORKER_RUNNING,
+    UMCG_WORKER_PAUSED,
+    UMCG_WORKER_BLOCKED,
+    UMCG_WORKER_WAITING,
+};
+
+/* flags ORed with worker status enum value */
+#define UMCG_WORKER_TIMEOUT U32_FROM_BIT(31)
+
+enum umcg_event_type {
+    UMCG_WE_BLOCK = 1,
+    UMCG_WE_WAKE,
+    UMCG_WE_WAIT,
+    UMCG_WE_EXIT,
+    UMCG_WE_TIMEOUT,
+    UMCG_WE_PREEMPT,
+};
+
+#define UMCG_PREEMPT_INTERVAL   microseconds(RUNLOOP_TIMER_MAX_PERIOD_US)
+
+//#define UMCG_DEBUG
+#ifdef UMCG_DEBUG
+#define umcg_debug(x, ...)  tprintf(sym(umcg), 0, x "\n", ##__VA_ARGS__)
+#else
+#define umcg_debug(x, ...)
+#endif
+
+declare_closure_struct(0, 2, void, umcg_worker_timeout,
+                       u64, expiry, u64, overruns);
+typedef struct umcg_worker {
+    struct rbnode node;
+    struct list l;
+    thread t;
+    u64 id;
+    enum umcg_worker_status status;
+    timestamp start_time;
+    enum umcg_event_type event;
+    blockq server_bq;
+    u64 *server_event;
+    struct timer tmr;
+    closure_struct(umcg_worker_timeout, timeout_handler);
+} *umcg_worker;
+
+declare_closure_struct(0, 2, int, umcg_worker_compare,
+                       rbnode, a, rbnode, b);
+static struct {
+    heap h;
+    struct rbtree workers;
+    closure_struct(umcg_worker_compare, worker_compare);
+    struct list idle_workers;
+    struct spinlock lock;
+    struct blockq server_bq;    /* used by idle servers, i.e. servers not attached to any worker */
+    void (*thread_pause)(struct context *);
+    void (*thread_schedule_return)(struct context *);
+    void (*syscall_pause)(struct context *);
+    void (*thread_free)(void *);
+    u32 wake_idle_server;
+} umcg;
+
+#define umcg_lock()     spin_lock(&umcg.lock)
+#define umcg_unlock()   spin_unlock(&umcg.lock)
+
+static sysreturn umcg_unregister(umcg_worker worker);
+
+define_closure_function(0, 2, int, umcg_worker_compare,
+                        rbnode, a, rbnode, b)
+{
+    thread ta = ((umcg_worker)a)->t;
+    thread tb = ((umcg_worker)b)->t;
+    return ta == tb ? 0 : (ta < tb ? -1 : 1);
+}
+
+static umcg_worker umcg_get_worker(thread t)
+{
+    struct umcg_worker k = {
+        .t = t,
+    };
+    umcg_lock();
+    umcg_worker worker = (umcg_worker)rbtree_lookup(&umcg.workers, &k.node);
+    umcg_unlock();
+    return worker;
+
+}
+
+static void umcg_worker_event_idle(umcg_worker worker, enum umcg_event_type event)
+{
+    worker->event = event;
+    umcg_lock();
+    list_push_back(&umcg.idle_workers, &worker->l);
+    umcg_unlock();
+    blockq_wake_one(&umcg.server_bq);
+}
+
+static void umcg_worker_event_to_server(umcg_worker worker, enum umcg_event_type event)
+{
+    *worker->server_event = worker->id | event;
+    blockq bq = worker->server_bq;
+    blockq_wake_one(bq);
+    blockq_release(bq);
+}
+
+define_closure_function(0, 2, void, umcg_worker_timeout,
+                        u64, expiry, u64, overruns)
+{
+    umcg_debug("worker timeout (%ld)", overruns);
+    if (overruns == timer_disabled)
+        return;
+    umcg_worker worker = struct_from_field(closure_self(), umcg_worker, timeout_handler);
+    if (compare_and_swap_32(&worker->status, UMCG_WORKER_WAITING, UMCG_WORKER_IDLE))
+        umcg_worker_event_idle(worker, UMCG_WE_TIMEOUT);
+    else if (!compare_and_swap_32(&worker->status, UMCG_WORKER_IDLE,
+                                  UMCG_WORKER_IDLE | UMCG_WORKER_TIMEOUT))
+        return;
+    set_syscall_return(worker->t, -ETIMEDOUT);
+}
+
+static void umcg_syscall_pause(context ctx)
+{
+    thread t = ((syscall_context)ctx)->t;
+    umcg_worker worker = umcg_get_worker(t);
+    if ((worker != INVALID_ADDRESS) &&
+        compare_and_swap_32(&worker->status, UMCG_WORKER_PAUSED, UMCG_WORKER_BLOCKED)) {
+        blockq bq = worker->server_bq;
+        worker->server_bq = 0;
+        *worker->server_event = worker->id | UMCG_WE_BLOCK;
+        blockq_wake_one(bq);
+        blockq_release(bq);
+    }
+    ctx->pause = umcg.syscall_pause;
+    ctx->pause(ctx);
+}
+
+static void umcg_worker_pause(context ctx)
+{
+    thread t = (thread)ctx;
+    syscall_context sc = t->syscall;
+    if (sc) {
+        umcg_worker worker = umcg_get_worker(t);
+        worker->status = UMCG_WORKER_PAUSED;
+        umcg.syscall_pause = sc->uc.kc.context.pause;
+        sc->uc.kc.context.pause = umcg_syscall_pause;
+    }
+    umcg.thread_pause(ctx);
+}
+
+static void umcg_worker_schedule_return(context ctx)
+{
+    umcg_worker worker = umcg_get_worker((thread)ctx);
+    if (compare_and_swap_32(&worker->status, UMCG_WORKER_BLOCKED, UMCG_WORKER_IDLE)) {
+        blockq server_bq = worker->server_bq;
+        if (server_bq) {
+            blockq_wake_one(server_bq);
+            blockq_release(server_bq);
+        }
+        umcg_worker_event_idle(worker, UMCG_WE_WAKE);
+    } else if (kern_now(CLOCK_ID_MONOTONIC_RAW) >= worker->start_time + UMCG_PREEMPT_INTERVAL) {
+        worker->status = UMCG_WORKER_RUNNABLE;
+        umcg_worker_event_to_server(worker, UMCG_WE_PREEMPT);
+    } else {
+        worker->status = UMCG_WORKER_RUNNING;
+        umcg.thread_schedule_return(ctx);
+    }
+}
+
+/* Called if a worker thread terminates without unregistering itself as a worker. */
+static void umcg_worker_thread_free(void *__self)
+{
+    umcg_debug("worker thread free");
+    closure_ref(free_thread, ft) = __self;
+    umcg_unregister(umcg_get_worker(closure_member(free_thread, ft, t)));
+    apply((thunk)ft);   /* invoke the real thread refcount completion */
+}
+
+static sysreturn umcg_register_worker(thread t, u64 id)
+{
+    umcg_debug("register worker 0x%lx", id);
+    if (id & UMCG_WORKER_EVENT_MASK)
+        return -EINVAL;
+    umcg_worker worker = allocate(umcg.h, sizeof(*worker));
+    if (worker == INVALID_ADDRESS)
+        return -ENOMEM;
+    worker->t = t;
+    worker->id = id;
+    worker->status = UMCG_WORKER_IDLE;
+    init_timer(&worker->tmr);
+    init_closure(&worker->timeout_handler, umcg_worker_timeout);
+    umcg_lock();
+    init_rbnode(&worker->node);
+    if (!rbtree_insert_node(&umcg.workers, &worker->node)) {
+        umcg_unlock();
+        deallocate(umcg.h, worker, sizeof(*worker));
+        return -EINVAL;
+    }
+
+    /* Replace thread context callbacks to be able to generate UMCG_WE_BLOCK and UMCG_WE_PRREMPT
+     * events. */
+    umcg.thread_pause = t->context.pause;
+    t->context.pause = umcg_worker_pause;
+    umcg.thread_schedule_return = t->context.schedule_return;
+    t->context.schedule_return = umcg_worker_schedule_return;
+
+    worker->event = UMCG_WE_WAKE;
+    list_push_back(&umcg.idle_workers, &worker->l);
+    umcg_unlock();
+    blockq_wake_one(&umcg.server_bq);
+
+    /* Replace the thread refcount completion to handle cases where a thread terminates without
+     * unregistering itself as a worker. */
+    umcg.thread_free = *t->context.refcount.completion;
+    *t->context.refcount.completion = umcg_worker_thread_free;
+
+    set_syscall_return(t, 0);
+    return thread_maybe_sleep_uninterruptible(t);
+}
+
+static sysreturn umcg_unregister(umcg_worker worker)
+{
+    umcg_debug("unregister %p", worker);
+    if (worker != INVALID_ADDRESS) {
+        umcg_lock();
+        rbtree_remove_node(&umcg.workers, &worker->node);
+        umcg_unlock();
+        thread t = worker->t;
+        context ctx = &t->context;
+        ctx->pause = umcg.thread_pause;
+        ctx->schedule_return = umcg.thread_schedule_return;
+        syscall_context sc = t->syscall;
+        if (sc)
+            sc->uc.kc.context.pause = umcg.syscall_pause;
+        *t->context.refcount.completion = umcg.thread_free;
+        umcg_worker_event_to_server(worker, UMCG_WE_EXIT);
+        deallocate(umcg.h, worker, sizeof(*worker));
+    }
+    return 0;
+}
+
+static sysreturn umcg_server_get_events(u64 *events, u64 event_sz)
+{
+    sysreturn rv = 0;
+    umcg_lock();
+    while (event_sz > 1) {
+        struct list *l = list_get_next(&umcg.idle_workers);
+        if (!l)
+            break;
+        umcg_worker worker = struct_from_field(l, umcg_worker, l);
+        umcg_debug("worker 0x%lx event %ld", worker->id, worker->event);
+        u64 event = worker->id | worker->event;
+        if (!set_user_value(events, event)) {
+            if (rv == 0)
+                rv = -EFAULT;
+            break;
+        }
+        rv++;
+        events++;
+        event_sz--;
+
+        /* To check for worker timeout, use compare_and_swap to protect against race with timeout
+         * handler. */
+        if ((worker->event == UMCG_WE_WAIT) &&
+            !compare_and_swap_32(&worker->status, UMCG_WORKER_IDLE,
+                                 UMCG_WORKER_IDLE | UMCG_WORKER_TIMEOUT)) {
+            event = worker->id | UMCG_WE_TIMEOUT;
+            if (!set_user_value(events, event)) {
+                if (rv == 1)
+                    rv = -EFAULT;
+                break;
+            }
+            rv++;
+            events++;
+            event_sz--;
+        }
+
+        worker->status = UMCG_WORKER_RUNNABLE;
+        list_delete(l);
+    }
+    if (event_sz > 0) {
+        u64 event = 0;
+        set_user_value(events, event);
+    }
+    umcg_unlock();
+    return rv;
+}
+
+closure_function(1, 1, sysreturn, umcg_server_wait_worker_bh,
+                 umcg_worker, worker,
+                 u64, flags)
+{
+    syscall_context ctx = (syscall_context)get_current_context(current_cpu());
+    sysreturn rv;
+    if (flags & BLOCKQ_ACTION_NULLIFY) {
+        rv = -ERESTARTSYS;
+        goto out;
+    }
+    if (bound(worker)->status == UMCG_WORKER_BLOCKED)
+        return blockq_block_required(&ctx->uc, flags);
+    rv = 0;
+  out:
+    closure_finish();
+    return syscall_return(ctx->t, rv);
+}
+
+closure_function(3, 1, sysreturn, umcg_server_wait_bh,
+                 timestamp, timeout, u64 *, events, u64, event_sz,
+                 u64, flags)
+{
+    syscall_context ctx = (syscall_context)get_current_context(current_cpu());
+    sysreturn rv;
+    if (flags & BLOCKQ_ACTION_TIMEDOUT) {
+        rv = -ETIMEDOUT;
+        goto out;
+    }
+    if (flags & BLOCKQ_ACTION_NULLIFY) {
+        rv = bound(timeout) ? -EINTR : -ERESTARTSYS;
+        goto out;
+    }
+    rv = umcg_server_get_events(bound(events), bound(event_sz));
+    if ((rv == 0) && !compare_and_swap_32(&umcg.wake_idle_server, true, false))
+        return blockq_block_required(&ctx->uc, flags);
+    if (rv > 0)
+        rv = 0;
+  out:
+    closure_finish();
+    return syscall_return(ctx->t, rv);
+}
+
+closure_function(3, 1, sysreturn, umcg_server_ctx_switch_bh,
+                 u64, event, u64 *, events, u64, event_sz,
+                 u64, flags)
+{
+    syscall_context ctx = (syscall_context)get_current_context(current_cpu());
+    sysreturn rv;
+    if (flags & BLOCKQ_ACTION_NULLIFY) {
+        rv = -ERESTARTSYS;
+        goto out;
+    }
+    u64 event = bound(event);
+    if (!event)
+        return blockq_block_required(&ctx->uc, flags);
+    u64 *events = bound(events);
+    u64 event_sz = bound(event_sz);
+    if (!set_user_value(events, event)) {
+        rv = -EFAULT;
+        goto out;
+    }
+    if (event_sz > 1) {
+        rv = umcg_server_get_events(events + 1, event_sz - 1);
+        if (rv > 0)
+            rv = 0;
+    } else {
+        rv = 0;
+    }
+  out:
+    closure_finish();
+    return syscall_return(ctx->t, rv);
+}
+
+static sysreturn umcg_wait(thread t, int next_tid, u64 abs_timeout, u64 *events, u64 event_sz)
+{
+    umcg_debug("wait tid %d, timeout %ld", next_tid, abs_timeout);
+    umcg_worker worker = umcg_get_worker(t);
+    if (worker == INVALID_ADDRESS) {
+        if (next_tid) {
+            if (abs_timeout || events || event_sz)
+                return -EINVAL;
+            thread next_t = thread_from_tid(t->p, next_tid);
+            if (next_t == INVALID_ADDRESS)
+                return -ESRCH;
+            umcg_worker next = umcg_get_worker(next_t);
+            thread_release(next_t);
+            if (next == INVALID_ADDRESS)
+                return -EINVAL;
+            blockq_action ba = contextual_closure(umcg_server_wait_worker_bh, next);
+            if (ba == INVALID_ADDRESS)
+                return -ENOMEM;
+            blockq bq = t->thread_bq;
+            next->server_bq = bq;
+            blockq_reserve(bq);
+            return blockq_check(bq, ba, false);
+        }
+        if (event_sz < 2)   /* there must be room for 2 events */
+            return -EINVAL;
+        if (abs_timeout == 1) {
+            sysreturn  rv = umcg_server_get_events(events, event_sz);
+            if (rv > 0)
+                return 0;
+            return (rv == 0) ? -ETIMEDOUT : rv;
+        }
+        timestamp ts = nanoseconds(abs_timeout);
+        blockq_action ba = contextual_closure(umcg_server_wait_bh, ts, events, event_sz);
+        if (ba == INVALID_ADDRESS)
+            return -ENOMEM;
+        return blockq_check_timeout(&umcg.server_bq, ba, false, CLOCK_ID_REALTIME, ts, true);
+    } else {
+        if (next_tid || events || event_sz)
+            return -EINVAL;
+        worker->status = UMCG_WORKER_WAITING;
+        if (abs_timeout)
+            register_timer(kernel_timers, &worker->tmr, CLOCK_ID_REALTIME, nanoseconds(abs_timeout),
+                           true, 0, (timer_handler)&worker->timeout_handler);
+        set_syscall_return(t, 0);
+        umcg_worker_event_to_server(worker, UMCG_WE_WAIT);
+        return thread_maybe_sleep_uninterruptible(t);
+    }
+}
+
+static sysreturn umcg_ctx_switch(thread t, int next_tid, u64 abs_timeout, u64 *events, u64 event_sz)
+{
+    umcg_debug("ctx switch tid %d, timeout %ld", next_tid, abs_timeout);
+    thread next_t = thread_from_tid(t->p, next_tid);
+    if (next_t == INVALID_ADDRESS)
+        return -ESRCH;
+    umcg_worker next = umcg_get_worker(next_t);
+    thread_release(next_t);
+    if (next == INVALID_ADDRESS)
+        return -EINVAL;
+    blockq_action ba = 0;
+    umcg_worker worker = umcg_get_worker(t);
+    if (worker == INVALID_ADDRESS) {
+        if (abs_timeout || (event_sz <= 0))
+            return -EINVAL;
+        ba = contextual_closure(umcg_server_ctx_switch_bh, 0, events, event_sz);
+        if (ba == INVALID_ADDRESS)
+            return -ENOMEM;
+        if (!compare_and_swap_32(&next->status, UMCG_WORKER_RUNNABLE, UMCG_WORKER_RUNNING) &&
+            !compare_and_swap_32(&next->status, UMCG_WORKER_WAITING, UMCG_WORKER_RUNNING)) {
+            deallocate_closure(ba);
+            return -EINVAL;
+        }
+        next->server_event = &closure_member(umcg_server_ctx_switch_bh, ba, event);
+        blockq server_bq = t->thread_bq;
+        next->server_bq = server_bq;
+        blockq_reserve(server_bq);
+    } else {
+        if (!compare_and_swap_32(&next->status, UMCG_WORKER_RUNNABLE, UMCG_WORKER_RUNNING))
+            return -EINVAL;
+        worker->status = UMCG_WORKER_IDLE;
+        umcg_worker_event_idle(worker, UMCG_WE_WAIT);
+        if (abs_timeout)
+            register_timer(kernel_timers, &worker->tmr, CLOCK_ID_REALTIME, nanoseconds(abs_timeout),
+                           true, 0, (timer_handler)&worker->timeout_handler);
+        next->server_event = worker->server_event;
+        next->server_bq = worker->server_bq;
+        set_syscall_return(t, 0);
+    }
+    remove_timer(kernel_timers, &next->tmr, 0);
+    next->start_time = kern_now(CLOCK_ID_MONOTONIC_RAW);
+    if (next_t->syscall)
+        syscall_return(next_t, get_syscall_return(next_t));
+    else
+        schedule_thread(next_t);
+    if (worker == INVALID_ADDRESS)
+        return blockq_check(t->thread_bq, ba, false);
+    else
+        return thread_maybe_sleep_uninterruptible(t);
+}
+
+sysreturn umcg_ctl(u64 flags, u64 cmd, int next_tid, u64 abs_timeout, u64 *events, int event_sz)
+{
+    umcg_debug("cmd %d", cmd);
+    thread t = current;
+    switch (cmd) {
+    case UMCG_REGISTER_WORKER:
+        if (flags || next_tid || events || event_sz)
+            return -EINVAL;
+        return umcg_register_worker(t, abs_timeout);
+    case UMCG_REGISTER_SERVER:
+        if (flags || next_tid || abs_timeout || events || event_sz)
+            return -EINVAL;
+        break;
+    case UMCG_UNREGISTER:
+        if (flags || next_tid || abs_timeout || events || event_sz)
+            return -EINVAL;
+        return umcg_unregister(umcg_get_worker(t));
+    case UMCG_WAKE:
+        if (flags || next_tid || abs_timeout || events || event_sz)
+            return -EINVAL;
+        umcg.wake_idle_server = true;
+        if ((blockq_wake_one(&umcg.server_bq) == INVALID_ADDRESS) &&
+            compare_and_swap_32(&umcg.wake_idle_server, true, false))
+            return -EAGAIN;
+        break;
+    case UMCG_WAIT:
+        if (flags & ~UMCG_CMD_KNOWN_FLAGS)
+            return -EINVAL;
+        return umcg_wait(t, next_tid, abs_timeout, events, event_sz);
+    case UMCG_CTX_SWITCH:
+        if (flags)
+            return -EINVAL;
+        return umcg_ctx_switch(t, next_tid, abs_timeout, events, event_sz);
+    default:
+        return -EINVAL;
+    }
+    return 0;
+}
+
+int init(status_handler complete)
+{
+    umcg.h = heap_locked(get_kernel_heaps());
+    init_rbtree(&umcg.workers, init_closure(&umcg.worker_compare, umcg_worker_compare), 0);
+    list_init(&umcg.idle_workers);
+    blockq_init(&umcg.server_bq, ss("umcg servers"));
+    spin_lock_init(&umcg.lock);
+    register_syscall(linux_syscalls, umcg_ctl, umcg_ctl, SYSCALL_F_SET_PROC);
+    return KLIB_INIT_OK;
+}
diff --git a/src/unix/blockq.c b/src/unix/blockq.c
index ec807180a..52dfc5c4e 100644
--- a/src/unix/blockq.c
+++ b/src/unix/blockq.c
@@ -331,19 +331,23 @@ define_closure_function(1, 0, void, free_blockq,
     deallocate(bq->h, bq, sizeof(struct blockq));
 }
 
-blockq allocate_blockq(heap h, sstring name)
+void blockq_init(blockq bq, sstring name)
 {
-    blockq_debug("name \"%s\"\n", name);
-    blockq bq = allocate(h, sizeof(struct blockq));
-    if (bq == INVALID_ADDRESS)
-        return bq;
-
-    bq->h = h;
     bq->name = name;
     bq->wake = false;
     spin_lock_init(&bq->lock);
     list_init(&bq->waiters_head);
     init_refcount(&bq->refcount, 1, init_closure(&bq->free, free_blockq, bq));
+}
+
+blockq allocate_blockq(heap h, sstring name)
+{
+    blockq_debug("name \"%s\"\n", name);
+    blockq bq = allocate(h, sizeof(struct blockq));
+    if (bq != INVALID_ADDRESS) {
+        bq->h = h;
+        blockq_init(bq, name);
+    }
     return bq;
 }
 
diff --git a/src/unix/unix_internal.h b/src/unix/unix_internal.h
index 9fe6cd6ca..2f86bd4c6 100644
--- a/src/unix/unix_internal.h
+++ b/src/unix/unix_internal.h
@@ -219,6 +219,7 @@ struct blockq {
     closure_struct(free_blockq, free);
 };
 
+void blockq_init(blockq bq, sstring name);
 blockq allocate_blockq(heap h, sstring name);
 void deallocate_blockq(blockq bq);
 void blockq_thread_init(unix_context t);
diff --git a/src/x86_64/unix_syscalls.h b/src/x86_64/unix_syscalls.h
index c526bda45..45c3b63cf 100644
--- a/src/x86_64/unix_syscalls.h
+++ b/src/x86_64/unix_syscalls.h
@@ -335,4 +335,4 @@
 #define SYS_io_uring_register			427
 #define SYS_clone3				435
 
-#define SYS_MAX 436
+#define SYS_MAX 451
diff --git a/test/runtime/Makefile b/test/runtime/Makefile
index 96561da85..5bb5187c4 100644
--- a/test/runtime/Makefile
+++ b/test/runtime/Makefile
@@ -309,8 +309,15 @@ LDFLAGS-readv=		-static
 ifeq ($(ARCH),x86_64)
 
 PROGRAMS+= \
+	umcg \
 	vsyscall \
 
+SRCS-umcg= \
+	$(CURDIR)/umcg.c \
+	$(SRCDIR)/unix_process/unix_process_runtime.c \
+	$(RUNTIME)
+LIBS-umcg=	-lpthread
+
 SRCS-vsyscall= \
 	$(CURDIR)/vsyscall.c \
 	$(SRCDIR)/unix_process/ssp.c
diff --git a/test/runtime/umcg.c b/test/runtime/umcg.c
new file mode 100644
index 000000000..77588984f
--- /dev/null
+++ b/test/runtime/umcg.c
@@ -0,0 +1,699 @@
+#define _GNU_SOURCE
+#include <errno.h>
+#include <linux/futex.h>
+#include <pthread.h>
+#include <sys/syscall.h>
+#include <unistd.h>
+
+#include <runtime.h>
+
+#include "../test_utils.h"
+
+#define __NR_umcg_ctl  450
+
+#define UMCG_WORKER_ID_SHIFT    5
+#define UMCG_WORKER_EVENT_MASK  ((1 << UMCG_WORKER_ID_SHIFT) - 1)
+
+#define UMCG_WAIT_FLAG_INTERRUPTED  (1ull)
+
+enum umcg_cmd {
+    UMCG_REGISTER_WORKER = 1,
+    UMCG_REGISTER_SERVER,
+    UMCG_UNREGISTER,
+    UMCG_WAKE,
+    UMCG_WAIT,
+    UMCG_CTX_SWITCH,
+};
+
+enum umcg_event_type {
+    UMCG_WE_BLOCK = 1,
+    UMCG_WE_WAKE,
+    UMCG_WE_WAIT,
+    UMCG_WE_EXIT,
+    UMCG_WE_TIMEOUT,
+    UMCG_WE_PREEMPT,
+};
+
+static int umcg_test_duration = 10; /* expressed in seconds */
+
+static inline int sys_umcg_ctl(u64 flags, u64 cmd, pid_t next_tid, u64 abs_timeout,
+                               u64 *events, int event_sz)
+{
+    return syscall(__NR_umcg_ctl, flags, cmd, next_tid, abs_timeout, events, event_sz);
+}
+
+struct umcg_test_worker {
+    struct list node;
+    pid_t tid;
+};
+
+struct umcg_test_server {
+    struct list node;
+    pid_t cur;
+    int workers;
+};
+
+struct condvar_test_syncdata {
+    volatile int worker_task;
+    pthread_mutex_t *mutex;
+    pthread_cond_t *cond;
+};
+
+static int umcg_test_worker_add(struct umcg_test_server *server, pid_t foo)
+{
+    struct umcg_test_worker *task = malloc(sizeof(*task));
+
+    if (task == NULL)
+        return -1;
+    task->tid = foo;
+    list_push_back(&server->node, &task->node);
+    return 0;
+}
+
+static pid_t umcg_test_worker_pick(struct umcg_test_server *server)
+{
+    struct umcg_test_worker *first;
+    pid_t tid;
+
+    if (list_empty(&server->node))
+        return 0;
+    first = struct_from_list(list_begin(&server->node), struct umcg_test_worker *, node);
+    list_delete(&first->node);
+    tid = first->tid;
+    free(first);
+    return tid;
+}
+
+static int umcg_wait_retry(u64 worker_id, u64 *events, u64 event_sz)
+{
+    u64 flags = 0;
+    int ret;
+
+    do  {
+        ret = sys_umcg_ctl(flags, UMCG_WAIT, worker_id >> UMCG_WORKER_ID_SHIFT, 0,
+                           events, event_sz);
+        flags = UMCG_WAIT_FLAG_INTERRUPTED;
+    } while (ret && (errno == EINTR));
+    return ret;
+}
+
+static void umcg_yield(void)
+{
+    test_assert(umcg_wait_retry(0, NULL, 0) == 0);
+}
+
+static u64 umcg_wait_any_worker(enum umcg_event_type event)
+{
+    const int event_sz = 2;
+    u64 events[event_sz];
+
+    test_assert(umcg_wait_retry(0, events, event_sz) == 0);
+    test_assert(((events[0] & UMCG_WORKER_EVENT_MASK) == event) && (events[1] == 0));
+    return events[0] & ~UMCG_WORKER_EVENT_MASK;
+}
+
+static void umcg_assert_worker_event(u64 event, u64 worker_id, enum umcg_event_type type)
+{
+    test_assert((event & UMCG_WORKER_EVENT_MASK) == type);
+    test_assert((event & ~UMCG_WORKER_EVENT_MASK) == worker_id);
+}
+
+static void umcg_ctxsw_assert_worker_event(u64 worker_id, enum umcg_event_type event)
+{
+    const int event_sz = 2;
+    u64 events[event_sz];
+
+    test_assert(sys_umcg_ctl(0, UMCG_CTX_SWITCH, worker_id >> UMCG_WORKER_ID_SHIFT, 0,
+                             events, event_sz) == 0);
+    umcg_assert_worker_event(events[0], worker_id, event);
+    test_assert(events[1] == 0);
+}
+
+static volatile boolean done = false;
+
+static void umcg_test_check_done(struct timespec *start)
+{
+    struct timespec now;
+
+    clock_gettime(CLOCK_REALTIME, &now);
+    if (now.tv_sec < start->tv_sec + umcg_test_duration)
+        return;
+    if ((now.tv_nsec >= start->tv_nsec) || (now.tv_sec > start->tv_sec + umcg_test_duration))
+        done = true;
+}
+
+/* always running worker */
+static void *umcg_demo_worker_a(void *arg)
+{
+    struct umcg_test_server *server = arg;
+    pid_t tid;
+    unsigned long i = 0;
+    int ret;
+
+    tid = syscall(SYS_gettid);
+    printf("A == %d\n", tid);
+    ret = sys_umcg_ctl(0, UMCG_REGISTER_WORKER, 0, ((u64)tid) << UMCG_WORKER_ID_SHIFT, NULL, 0);
+    if (ret)
+        test_perror("umcg_ctl(A)");
+    __atomic_add_fetch(&server->workers, 1, __ATOMIC_RELAXED);
+    while (!done) {
+        int x = i++;
+
+        if (!(x % 1000000)) {
+            putchar('.');
+            fflush(stdout);
+        }
+        if (!(x % 10000000))
+            umcg_yield();
+    }
+    printf("A == done\n");
+    __atomic_add_fetch(&server->workers, -1, __ATOMIC_RELAXED);
+    ret = sys_umcg_ctl(0, UMCG_UNREGISTER, 0, 0, NULL, 0);
+    if (ret)
+        test_perror("umcg_ctl(~A)");
+    return NULL;
+}
+
+static void *umcg_demo_worker_b(void *arg)
+{
+    struct umcg_test_server *server = arg;
+    pid_t tid;
+    int ret;
+
+    tid = syscall(SYS_gettid);
+    printf("B == %d\n", tid);
+    ret = sys_umcg_ctl(0, UMCG_REGISTER_WORKER, 0, ((u64)tid) << UMCG_WORKER_ID_SHIFT, NULL, 0);
+    if (ret)
+        test_perror("umcg_ctl(B)");
+    __atomic_add_fetch(&server->workers, 1, __ATOMIC_RELAXED);
+    while (!done) {
+        printf("B\n");
+        sleep(1);
+    }
+    printf("B == done\n");
+    __atomic_add_fetch(&server->workers, -1, __ATOMIC_RELAXED);
+    ret = sys_umcg_ctl(0, UMCG_UNREGISTER, 0, 0, NULL, 0);
+    if (ret)
+        test_perror("umcg_ctl(~B)");
+    return NULL;
+}
+
+static void *umcg_demo_worker_c(void *arg)
+{
+    struct umcg_test_server *server = arg;
+    pid_t tid;
+    int ret;
+
+    tid = syscall(SYS_gettid);
+    printf("C == %d\n", tid);
+    ret = sys_umcg_ctl(0, UMCG_REGISTER_WORKER, 0, ((u64)tid) << UMCG_WORKER_ID_SHIFT, NULL, 0);
+    if (ret)
+        test_perror("umcg_ctl(C)");
+    __atomic_add_fetch(&server->workers, 1, __ATOMIC_RELAXED);
+    while (!done) {
+        printf("C\n");
+        sleep(2);
+    }
+    printf("C == done\n");
+    __atomic_add_fetch(&server->workers, -1, __ATOMIC_RELAXED);
+    ret = sys_umcg_ctl(0, UMCG_UNREGISTER, 0, 0, NULL, 0);
+    if (ret)
+        perror("umcg_ctl(~C)");
+    return NULL;
+}
+
+static int umcg_demo(void)
+{
+    struct umcg_test_server server = { };
+    const int worker_count = 3;
+    pthread_t worker[worker_count];
+    const int event_sz = worker_count * 2;
+    u64 events[event_sz];
+    struct timespec start;
+    int ret;
+
+    list_init(&server.node);
+    ret = sys_umcg_ctl(0, UMCG_REGISTER_SERVER, 0, 0, NULL, 0);
+    if (ret)
+        test_perror("umcg_ctl(server)");
+    pthread_create(&worker[0], NULL, umcg_demo_worker_a, &server);
+    pthread_create(&worker[1], NULL, umcg_demo_worker_b, &server);
+    pthread_create(&worker[2], NULL, umcg_demo_worker_c, &server);
+    clock_gettime(CLOCK_REALTIME, &start);
+    while (!(done && !__atomic_load_n(&server.workers, __ATOMIC_RELAXED))) {
+        server.cur = umcg_test_worker_pick(&server);
+        if (!server.cur) {
+            putchar('x');
+            ret = umcg_wait_retry(0, events, event_sz);
+        } else {
+            printf("pick: %d\n", server.cur);
+            ret = sys_umcg_ctl(0, UMCG_CTX_SWITCH, server.cur, 0, events, event_sz);
+        }
+        if (ret)
+            test_perror("server loop");
+        for (int i = 0; i < event_sz; i++) {
+            u64 event = events[i];
+
+            if (event == 0)
+                break;
+            switch (event & UMCG_WORKER_EVENT_MASK) {
+            case UMCG_WE_WAKE:
+            case UMCG_WE_WAIT:
+                if (umcg_test_worker_add(&server, event >> UMCG_WORKER_ID_SHIFT) < 0)
+                    test_error("cannot add runnable worker %lld", event >> UMCG_WORKER_ID_SHIFT);
+                break;
+            default:
+                printf("worker tid %lld, event %lld\n", event >> UMCG_WORKER_ID_SHIFT,
+                       event & UMCG_WORKER_EVENT_MASK);
+            }
+        }
+        umcg_test_check_done(&start);
+    }
+    pthread_join(worker[0], NULL);
+    pthread_join(worker[1], NULL);
+    pthread_join(worker[2], NULL);
+    return 0;
+}
+
+static void *umcg_perftest_worker(void *arg)
+{
+    test_assert(sys_umcg_ctl(0, UMCG_REGISTER_WORKER, 0,
+                             syscall(SYS_gettid) << UMCG_WORKER_ID_SHIFT, NULL, 0) == 0);
+    while (!done)
+        test_assert(sys_umcg_ctl(0, UMCG_WAIT, 0, 0, NULL, 0) == 0);
+    test_assert(sys_umcg_ctl(0, UMCG_UNREGISTER, 0, 0, NULL, 0) == 0);
+    return NULL;
+}
+
+static int umcg_perftest(void)
+{
+    pthread_t worker;
+    u64 worker_id;
+    struct timespec start;
+    long long cycles;
+
+    printf("UMCG performance test duration: %d seconds...\n", umcg_test_duration);
+    test_assert(sys_umcg_ctl(0, UMCG_REGISTER_SERVER, 0, 0, NULL, 0) == 0);
+    pthread_create(&worker, NULL, umcg_perftest_worker, NULL);
+    worker_id = umcg_wait_any_worker(UMCG_WE_WAKE);
+    clock_gettime(CLOCK_REALTIME, &start);
+    for (cycles = 0; !done; cycles++) {
+        umcg_ctxsw_assert_worker_event(worker_id, UMCG_WE_WAIT);
+        umcg_test_check_done(&start);
+    }
+    printf("Results: %lld cycles (%g cycles/sec)\n", cycles, cycles/ (double)umcg_test_duration);
+    umcg_ctxsw_assert_worker_event(worker_id, UMCG_WE_EXIT);
+    pthread_join(worker, NULL);
+    return 0;
+}
+
+static void *futex_perftest_worker(void *arg)
+{
+    int *word_ptr = arg;
+
+    while (!done) {
+        syscall(SYS_futex, word_ptr, FUTEX_WAIT | FUTEX_PRIVATE_FLAG, 0, 0, NULL, 0);
+        *word_ptr = 0;
+        syscall(SYS_futex, word_ptr, FUTEX_WAKE | FUTEX_PRIVATE_FLAG, 1, 0, NULL, 0);
+    }
+    return NULL;
+}
+
+static int futex_perftest(void)
+{
+    int futex_word;
+    pthread_t worker;
+    struct timespec start;
+    long long cycles;
+
+    printf("Futex performance test duration: %d seconds...\n", umcg_test_duration);
+    pthread_create(&worker, NULL, futex_perftest_worker, &futex_word);
+    clock_gettime(CLOCK_REALTIME, &start);
+    for (cycles = 0; !done; cycles++) {
+        futex_word = 1;
+        syscall(SYS_futex, &futex_word, FUTEX_WAKE | FUTEX_PRIVATE_FLAG, 1, 0, NULL, 0);
+        syscall(SYS_futex, &futex_word, FUTEX_WAIT | FUTEX_PRIVATE_FLAG, 1, 0, NULL, 0);
+        umcg_test_check_done(&start);
+    }
+    printf("Results: %lld cycles (%g cycles/sec)\n", cycles, cycles/ (double)umcg_test_duration);
+    futex_word = 1;
+    syscall(SYS_futex, &futex_word, FUTEX_WAKE | FUTEX_PRIVATE_FLAG, 1, 0, NULL, 0);
+    pthread_join(worker, NULL);
+    return 0;
+}
+
+static void *condvar_perftest_worker(void *arg)
+{
+    struct condvar_test_syncdata *syncdata = arg;
+    pthread_cond_t *cond = syncdata->cond;
+    pthread_mutex_t *mutex = syncdata->mutex;
+
+    while (!done) {
+        pthread_mutex_lock(mutex);
+        while (!syncdata->worker_task)
+            test_assert(pthread_cond_wait(cond, mutex) == 0);
+        syncdata->worker_task = 0;
+        pthread_mutex_unlock(mutex);
+        test_assert(pthread_cond_signal(cond) == 0);
+    }
+    return NULL;
+}
+
+static int condvar_perftest(void)
+{
+    pthread_mutex_t mutex = PTHREAD_MUTEX_INITIALIZER;
+    pthread_cond_t cond = PTHREAD_COND_INITIALIZER;
+    struct condvar_test_syncdata syncdata = {
+        .worker_task = 0,
+        .mutex = &mutex,
+        .cond = &cond,
+    };
+    pthread_t worker;
+    struct timespec start;
+    long long cycles;
+
+    printf("Condition variable performance test duration: %d seconds...\n", umcg_test_duration);
+    pthread_create(&worker, NULL, condvar_perftest_worker, &syncdata);
+    clock_gettime(CLOCK_REALTIME, &start);
+    for (cycles = 0; !done; cycles++) {
+        pthread_mutex_lock(&mutex);
+        while (syncdata.worker_task)
+            test_assert(pthread_cond_wait(&cond, &mutex) == 0);
+        syncdata.worker_task = 1;
+        pthread_mutex_unlock(&mutex);
+        test_assert(pthread_cond_signal(&cond) == 0);
+        umcg_test_check_done(&start);
+    }
+    printf("Results: %lld cycles (%g cycles/sec)\n", cycles, cycles/ (double)umcg_test_duration);
+    syncdata.worker_task = 1;
+    test_assert(pthread_cond_signal(&cond) == 0);
+    pthread_join(worker, NULL);
+    return 0;
+}
+
+static void *umcg_worker_dummy(void *arg)
+{
+    test_assert(sys_umcg_ctl(0, UMCG_REGISTER_WORKER, 0,
+                             syscall(SYS_gettid) << UMCG_WORKER_ID_SHIFT, NULL, 0) == 0);
+    test_assert(sys_umcg_ctl(0, UMCG_UNREGISTER, 0, 0, NULL, 0) == 0);
+    return NULL;
+}
+
+static void *umcg_worker_blocking(void *arg)
+{
+    test_assert(sys_umcg_ctl(0, UMCG_REGISTER_WORKER, 0,
+                             syscall(SYS_gettid) << UMCG_WORKER_ID_SHIFT, NULL, 0) == 0);
+    usleep(16 * 1024);
+    test_assert(sys_umcg_ctl(0, UMCG_UNREGISTER, 0, 0, NULL, 0) == 0);
+    return NULL;
+}
+
+static void *umcg_worker_wait_timeout(void *arg)
+{
+    struct timespec ts;
+
+    test_assert(sys_umcg_ctl(0, UMCG_REGISTER_WORKER, 0,
+                             syscall(SYS_gettid) << UMCG_WORKER_ID_SHIFT, NULL, 0) == 0);
+    clock_gettime(CLOCK_REALTIME, &ts);
+    test_assert(sys_umcg_ctl(0, UMCG_WAIT, 0, ts.tv_sec * BILLION + ts.tv_nsec, NULL, 0) == -1);
+    test_assert(errno == ETIMEDOUT);
+    test_assert(sys_umcg_ctl(0, UMCG_UNREGISTER, 0, 0, NULL, 0) == 0);
+    return NULL;
+}
+
+static void *umcg_worker_ctxsw_timeout(void *arg)
+{
+    u64 worker_id = *(u64 *)arg;
+    struct timespec ts;
+    int ret;
+
+    test_assert(sys_umcg_ctl(0, UMCG_REGISTER_WORKER, 0,
+                             syscall(SYS_gettid) << UMCG_WORKER_ID_SHIFT, NULL, 0) == 0);
+    clock_gettime(CLOCK_REALTIME, &ts);
+    ret = sys_umcg_ctl(0, UMCG_CTX_SWITCH, worker_id >> UMCG_WORKER_ID_SHIFT,
+                       ts.tv_sec * BILLION + ts.tv_nsec, NULL, 0);
+    test_assert((ret == 0) || ((ret < 0) && (errno == ETIMEDOUT)));
+    test_assert(sys_umcg_ctl(0, UMCG_UNREGISTER, 0, 0, NULL, 0) == 0);
+    return NULL;
+}
+
+static void *umcg_worker_preempted(void *arg)
+{
+    volatile int *worker_exit = arg;
+
+    test_assert(sys_umcg_ctl(0, UMCG_REGISTER_WORKER, 0,
+                             syscall(SYS_gettid) << UMCG_WORKER_ID_SHIFT, NULL, 0) == 0);
+    while (!*worker_exit);
+    test_assert(sys_umcg_ctl(0, UMCG_UNREGISTER, 0, 0, NULL, 0) == 0);
+    return NULL;
+}
+
+static void *umcg_worker_exiting(void *arg)
+{
+    u64 worker_id = syscall(SYS_gettid) << UMCG_WORKER_ID_SHIFT;
+    const int event_sz = 2;
+    u64 events[event_sz];
+
+    int ret;
+
+    test_assert(sys_umcg_ctl(0, UMCG_REGISTER_WORKER, 0, worker_id, NULL, 0) == 0);
+
+    /* try to register an already registered worker */
+    ret = sys_umcg_ctl(0, UMCG_REGISTER_WORKER, 0, worker_id, NULL, 0);
+    test_assert((ret < 0) && (errno == EINVAL));
+
+    /* try to context-switch to itself */
+    ret = sys_umcg_ctl(0, UMCG_CTX_SWITCH, worker_id >> UMCG_WORKER_ID_SHIFT, 0, NULL, 0);
+    test_assert((ret == -1) && (errno == EINVAL));
+
+    ret = sys_umcg_ctl(0, UMCG_WAIT, worker_id, 0, NULL, 0);
+    test_assert((ret < 0) && (errno == EINVAL));    /* non-zero next_tid */
+
+    ret = sys_umcg_ctl(0, UMCG_WAIT, 0, 0, events, 0);
+    test_assert((ret < 0) && (errno == EINVAL));    /* non-NULL events */
+
+    ret = sys_umcg_ctl(0, UMCG_WAIT, 0, 0, NULL, event_sz);
+    test_assert((ret == -1) && (errno == EINVAL));  /* non-zero event size */
+
+    return NULL;    /* exit thread without unregistering worker */
+}
+
+static void umcg_test_basic(void)
+{
+    pthread_t workers[2];
+    u64 worker_ids[2];
+    int ret;
+    const int event_sz = 2;
+    u64 events[event_sz];
+    int worker_exit;
+
+    test_assert(sys_umcg_ctl(0, UMCG_REGISTER_SERVER, 0, 0, NULL, 0) == 0);
+
+    pthread_create(&workers[0], NULL, umcg_worker_blocking, NULL);
+    worker_ids[0] = umcg_wait_any_worker(UMCG_WE_WAKE);
+    umcg_ctxsw_assert_worker_event(worker_ids[0], UMCG_WE_BLOCK);
+    test_assert(umcg_wait_retry(worker_ids[0], NULL, 0) == 0);  /* wait for worker to unblock */
+    test_assert(umcg_wait_any_worker(UMCG_WE_WAKE) == worker_ids[0]);
+    umcg_ctxsw_assert_worker_event(worker_ids[0], UMCG_WE_EXIT);
+    pthread_join(workers[0], NULL);
+
+    pthread_create(&workers[0], NULL, umcg_worker_wait_timeout, NULL);
+    worker_ids[0] = umcg_wait_any_worker(UMCG_WE_WAKE);
+    umcg_ctxsw_assert_worker_event(worker_ids[0], UMCG_WE_WAIT);
+    test_assert(umcg_wait_any_worker(UMCG_WE_TIMEOUT) == worker_ids[0]);
+    umcg_ctxsw_assert_worker_event(worker_ids[0], UMCG_WE_EXIT);
+    pthread_join(workers[0], NULL);
+
+    pthread_create(&workers[0], NULL, umcg_worker_dummy, NULL);
+    worker_ids[0] = umcg_wait_any_worker(UMCG_WE_WAKE);
+    pthread_create(&workers[1], NULL, umcg_worker_ctxsw_timeout, &worker_ids[0]);
+    worker_ids[1] = umcg_wait_any_worker(UMCG_WE_WAKE);
+    /* run second worker, which will context-switch to first worker, which will exit */
+    ret = sys_umcg_ctl(0, UMCG_CTX_SWITCH, worker_ids[1] >> UMCG_WORKER_ID_SHIFT, 0,
+                       events, event_sz);
+    test_assert(ret == 0);
+    umcg_assert_worker_event(events[0], worker_ids[0], UMCG_WE_EXIT);
+    test_assert(events[1] == 0);
+    /* retrieve events from second worker */
+    test_assert(umcg_wait_retry(0, events, event_sz) == 0);
+    umcg_assert_worker_event(events[0], worker_ids[1], UMCG_WE_WAIT);
+    if (events[1])
+        umcg_assert_worker_event(events[1], worker_ids[1], UMCG_WE_TIMEOUT);
+    umcg_ctxsw_assert_worker_event(worker_ids[1], UMCG_WE_EXIT);
+    pthread_join(workers[0], NULL);
+    pthread_join(workers[1], NULL);
+
+    worker_exit = 0;
+    pthread_create(&workers[0], NULL, umcg_worker_preempted, &worker_exit);
+    worker_ids[0] = umcg_wait_any_worker(UMCG_WE_WAKE);
+    umcg_ctxsw_assert_worker_event(worker_ids[0], UMCG_WE_PREEMPT);
+    worker_exit = 1;
+    umcg_ctxsw_assert_worker_event(worker_ids[0], UMCG_WE_EXIT);
+    pthread_join(workers[0], NULL);
+
+    pthread_create(&workers[0], NULL, umcg_worker_exiting, NULL);
+    worker_ids[0] = umcg_wait_any_worker(UMCG_WE_WAKE);
+    umcg_ctxsw_assert_worker_event(worker_ids[0], UMCG_WE_EXIT);
+    pthread_join(workers[0], NULL);
+
+    test_assert(sys_umcg_ctl(0, UMCG_UNREGISTER, 0, 0, NULL, 0) == 0);
+}
+
+static void *umcg_server_dummy(void *arg)
+{
+    const int event_sz = 2;
+    u64 events[event_sz];
+
+    test_assert(sys_umcg_ctl(0, UMCG_REGISTER_SERVER, 0, 0, NULL, 0) == 0);
+
+    /* wait for non-existing workers, until woken up by the main thread */
+    test_assert(umcg_wait_retry(0, events, event_sz) == 0);
+    test_assert((events[0] == 0));
+
+    test_assert(sys_umcg_ctl(0, UMCG_UNREGISTER, 0, 0, NULL, 0) == 0);
+    return NULL;
+}
+
+static void umcg_test_server2server(void)
+{
+    pthread_t server;
+    int ret;
+
+    test_assert(sys_umcg_ctl(0, UMCG_REGISTER_SERVER, 0, 0, NULL, 0) == 0);
+
+    pthread_create(&server, NULL, umcg_server_dummy, NULL);
+    do {    /* wake up the idle server that is waiting for non-existing workers */
+        ret = sys_umcg_ctl(0, UMCG_WAKE, 0, 0, NULL, 0);
+        if (ret)
+            test_assert((ret < 0) && (errno == EAGAIN));
+    } while (ret);
+    pthread_join(server, NULL);
+
+    test_assert(sys_umcg_ctl(0, UMCG_UNREGISTER, 0, 0, NULL, 0) == 0);
+}
+
+static void umcg_test_errors(void)
+{
+    struct timespec ts;
+    pthread_t worker;
+    u64 worker_id;
+    const int event_sz = 2;
+    u64 events[event_sz];
+    int ret;
+
+    ret = sys_umcg_ctl(0, UMCG_REGISTER_WORKER, 0, UMCG_WORKER_EVENT_MASK, NULL, 0);
+    test_assert((ret < 0) && (errno == EINVAL));    /* invalid worker id */
+
+    test_assert(sys_umcg_ctl(0, UMCG_REGISTER_SERVER, 0, 0, NULL, 0) == 0);
+
+    /* try to context-switch to itself */
+    ret = sys_umcg_ctl(0, UMCG_CTX_SWITCH, syscall(SYS_gettid), 0, events, event_sz);
+    test_assert((ret == -1) && (errno == EINVAL));
+
+    ret = sys_umcg_ctl(0, UMCG_WAIT, 0, 0, events, 1);
+    test_assert((ret == -1) && (errno == EINVAL));  /* there must be room for 2 events */
+
+    clock_gettime(CLOCK_REALTIME, &ts);
+    ret = sys_umcg_ctl(0, UMCG_WAIT, 0, ts.tv_sec * BILLION + ts.tv_nsec, events, event_sz);
+    test_assert((ret == -1) && (errno == ETIMEDOUT));
+
+    ret = sys_umcg_ctl(0, UMCG_WAIT, 0, 1, events, event_sz); /* poll without blocking */
+    test_assert((ret == -1) && (errno == ETIMEDOUT));
+
+    pthread_create(&worker, NULL, umcg_worker_dummy, NULL);
+    worker_id = umcg_wait_any_worker(UMCG_WE_WAKE);
+
+    ret = sys_umcg_ctl(0, UMCG_WAIT, worker_id >> UMCG_WORKER_ID_SHIFT, 0, events, 0);
+    test_assert((ret == -1) && (errno == EINVAL));  /* non-NULL events */
+
+    ret = sys_umcg_ctl(0, UMCG_WAIT, worker_id >> UMCG_WORKER_ID_SHIFT, 0, NULL, event_sz);
+    test_assert((ret == -1) && (errno == EINVAL));  /* non-zero event size */
+
+    ret = sys_umcg_ctl(0, UMCG_CTX_SWITCH, worker_id >> UMCG_WORKER_ID_SHIFT, 1, events, event_sz);
+    test_assert((ret == -1) && (errno == EINVAL));  /* non-zero timeout */
+
+    ret = sys_umcg_ctl(0, UMCG_CTX_SWITCH, worker_id >> UMCG_WORKER_ID_SHIFT, 0, events, 0);
+    test_assert((ret == -1) && (errno == EINVAL));  /* zero event size */
+
+    ret = sys_umcg_ctl(0, UMCG_CTX_SWITCH, worker_id >> UMCG_WORKER_ID_SHIFT, 0, FAULT_ADDR, 1);
+    test_assert((ret == -1) && (errno == EFAULT));
+    pthread_join(worker, NULL);
+
+    /* try to context-switch to a non-existing thread */
+    ret = sys_umcg_ctl(0, UMCG_CTX_SWITCH, worker_id >> UMCG_WORKER_ID_SHIFT, 0, events, event_sz);
+    test_assert((ret == -1) && (errno == ESRCH));
+
+    /* try to wake up an idle server when there aren't any */
+    ret = sys_umcg_ctl(0, UMCG_WAKE, 0, 0, NULL, 0);
+    test_assert((ret == -1) && (errno == EAGAIN));
+
+    test_assert(sys_umcg_ctl(0, UMCG_UNREGISTER, 0, 0, NULL, 0) == 0);
+}
+
+static void umcg_usage(const char *prog)
+{
+    printf("Usage: %s [-dufc] [-t <duration>]\n"
+           "Options:\n"
+           " -d: demo mode\n"
+           " -u: UMCG performance test\n"
+           " -f: futex performance test\n"
+           " -c: condition variable performance test\n"
+           " -t <duration>: (demo mode and performance tests) duration in seconds (default: 10)\n"
+           , prog);
+    exit(EXIT_FAILURE);
+}
+
+int main(int argc, char **argv)
+{
+    int opt;
+    enum {
+        mode_test,
+        mode_demo,
+        mode_umcg_perf,
+        mode_condvar_perf,
+        mode_futex_perf,
+    } mode = mode_test;
+
+    while ((opt = getopt(argc, argv, "dufct:")) != EOF) {
+        switch (opt) {
+        case 'd':
+            mode = mode_demo;
+            break;
+        case 'u':
+            mode = mode_umcg_perf;
+            break;
+        case 'f':
+            mode = mode_futex_perf;
+            break;
+        case 'c':
+            mode = mode_condvar_perf;
+            break;
+        case 't':
+            umcg_test_duration = atoi(optarg);
+            if (umcg_test_duration <= 0) {
+                printf("Invalid duration value '%s'\n", optarg);
+                umcg_usage(argv[0]);
+            }
+            break;
+        default:
+            umcg_usage(argv[0]);
+        }
+    }
+    switch (mode) {
+    case mode_test:
+        umcg_test_basic();
+        umcg_test_server2server();
+        umcg_test_errors();
+        printf("UMCG tests OK\n");
+        break;
+    case mode_demo:
+        return umcg_demo();
+    case mode_umcg_perf:
+        return umcg_perftest();
+    case mode_futex_perf:
+        return futex_perftest();
+    case mode_condvar_perf:
+        return condvar_perftest();
+    }
+    return 0;
+}
diff --git a/test/runtime/umcg.manifest b/test/runtime/umcg.manifest
new file mode 100644
index 000000000..a44b3a570
--- /dev/null
+++ b/test/runtime/umcg.manifest
@@ -0,0 +1,15 @@
+(
+    boot:(
+        children:(
+            klib:(children:(umcg:(contents:(host:output/klib/bin/umcg))))
+        )
+    )
+    children:(
+        umcg:(contents:(host:output/test/runtime/bin/umcg))
+        TEST-LIBS
+    )
+    klibs:bootfs
+    program:/umcg
+    environment:()
+    arguments:[umcg]
+)
